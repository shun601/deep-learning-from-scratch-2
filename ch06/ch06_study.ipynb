{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6章　ゲート付きRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 RNNの問題点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BPTTにおいて、勾配消失、勾配爆発が起こりやすい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 勾配消失、勾配爆発の原因"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2 # ミニバッチサイズ\n",
    "H = 3 # 隠れ状態ベクトルの次元数\n",
    "T = 20 # 時系列データの長さ\n",
    "\n",
    "dh = np.ones((N, H))\n",
    "np.random.seed(3)\n",
    "Wh = np.random.randn(H, H)\n",
    "\n",
    "norm_list = []\n",
    "# MutMulノードの数だけ、dhを更新\n",
    "for t in range(T):\n",
    "    dh = np.dot(dh, Wh.T)\n",
    "    # dhの大きさとして、ミニバッチにおける平均のN2ノルムを求めている.\n",
    "\n",
    "    norm = np.sqrt(np.sum(dh ** 2)) / N\n",
    "    norm_list.append(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'explading gradients')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(norm_list)\n",
    "plt.xlabel('time_step')\n",
    "plt.ylabel('norm')\n",
    "plt.title('explading gradients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2 # ミニバッチサイズ\n",
    "H = 3 # 隠れ状態ベクトルの次元数\n",
    "T = 20 # 時系列データの長さ\n",
    "\n",
    "dh = np.ones((N, H))\n",
    "np.random.seed(3)\n",
    "#Wh = np.random.randn(H, H)\n",
    "Wh = np.random.randn(H, H) * 0.5\n",
    "\n",
    "norm_list = []\n",
    "# MutMulノードの数だけ、dhを更新\n",
    "for t in range(T):\n",
    "    dh = np.dot(dh, Wh.T)\n",
    "    # dhの大きさとして、ミニバッチにおける平均のN2ノルムを求めている.\n",
    "\n",
    "    norm = np.sqrt(np.sum(dh ** 2)) / N\n",
    "    norm_list.append(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'vanishing gradients')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(norm_list)\n",
    "plt.xlabel('time_step')\n",
    "plt.ylabel('norm')\n",
    "plt.title('vanishing gradients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "行列の場合は、複数ある行列の特異値の中で、その最大値が１より大きいかどうかで、勾配の大きさの変化を予測することができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.4 勾配爆発への対策 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 勾配クリッピング "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW1 = np.random.rand(3, 3) * 10\n",
    "dW2 = np.random.rand(3, 3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    \"\"\"\n",
    "    grads: 勾配のリスト\n",
    "    max_norm: 閾値\n",
    "    \"\"\"\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "    \n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad += rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_grads(grads, max_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 勾配消失とLSTM\n",
    "- outputゲート O\n",
    "  - 隠れ状態のhtの出力を司る。\n",
    "- forgetゲート f\n",
    "  - 何を忘れるか？\n",
    "- 新しい記憶セル g\n",
    "  - 新しく覚えるべき情報を記憶セルに追加する\n",
    "  - 活性化にtanhを使用\n",
    "- inputゲート i\n",
    "  - gの各要素が新たに追加する情報としてどれだけ価値があるかを判断\n",
    "  - 追加する情報の取捨選択を行う\n",
    " \n",
    "  \n",
    "- LSTMの逆伝播では+ノードとxノード（アダマール積: 要素毎の積）しかないので、逆伝播の際に、毎時刻異なるゲート値によって要素毎の積の計算が行われる。\n",
    "- そのため、勾配消失を起こさない（もしくは起こしにくい）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 LSTMの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(object):\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "        \n",
    "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
    "        \n",
    "        # slice\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "        \n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(f)\n",
    "        o = sigmoid(o)\n",
    "        \n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "        \n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM(object):\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = None\n",
    "        H = Wh.shape[0]\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        \n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "            \n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            \n",
    "            \n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return hs\n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Ws.shape[0]\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "        \n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "                \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "            self.dh = dh\n",
    "            return dxs\n",
    "        \n",
    "    def set_staete(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 LSTMを使った言語モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnnlm(object):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "        \n",
    "        # 全ての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "    \n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()\n",
    "        \n",
    "    def save_params(self, file_name='Rnnlm.pkl'):\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(self.params, f)\n",
    "            \n",
    "    def load_params(self, file_name='Rnnlm.pkl'):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTBデータセットの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.test.txt ... \n",
      "Done\n",
      "| epoch 1 |  iter 1 / 1327 | time 0[s] | perplexity 10000.00\n",
      "| epoch 1 |  iter 21 / 1327 | time 5[s] | perplexity 3030.38\n",
      "| epoch 1 |  iter 41 / 1327 | time 8[s] | perplexity 1265.49\n",
      "| epoch 1 |  iter 61 / 1327 | time 12[s] | perplexity 974.93\n",
      "| epoch 1 |  iter 81 / 1327 | time 16[s] | perplexity 788.96\n",
      "| epoch 1 |  iter 101 / 1327 | time 19[s] | perplexity 639.49\n",
      "| epoch 1 |  iter 121 / 1327 | time 23[s] | perplexity 655.80\n",
      "| epoch 1 |  iter 141 / 1327 | time 28[s] | perplexity 606.15\n",
      "| epoch 1 |  iter 161 / 1327 | time 32[s] | perplexity 578.78\n",
      "| epoch 1 |  iter 181 / 1327 | time 36[s] | perplexity 578.69\n",
      "| epoch 1 |  iter 201 / 1327 | time 40[s] | perplexity 502.78\n",
      "| epoch 1 |  iter 221 / 1327 | time 44[s] | perplexity 489.69\n",
      "| epoch 1 |  iter 241 / 1327 | time 48[s] | perplexity 447.22\n",
      "| epoch 1 |  iter 261 / 1327 | time 52[s] | perplexity 459.47\n",
      "| epoch 1 |  iter 281 / 1327 | time 57[s] | perplexity 450.05\n",
      "| epoch 1 |  iter 301 / 1327 | time 61[s] | perplexity 384.66\n",
      "| epoch 1 |  iter 321 / 1327 | time 66[s] | perplexity 341.36\n",
      "| epoch 1 |  iter 341 / 1327 | time 70[s] | perplexity 402.05\n",
      "| epoch 1 |  iter 361 / 1327 | time 74[s] | perplexity 409.31\n",
      "| epoch 1 |  iter 381 / 1327 | time 79[s] | perplexity 336.29\n",
      "| epoch 1 |  iter 401 / 1327 | time 84[s] | perplexity 352.85\n",
      "| epoch 1 |  iter 421 / 1327 | time 88[s] | perplexity 340.36\n",
      "| epoch 1 |  iter 441 / 1327 | time 93[s] | perplexity 332.07\n",
      "| epoch 1 |  iter 461 / 1327 | time 97[s] | perplexity 329.89\n",
      "| epoch 1 |  iter 481 / 1327 | time 102[s] | perplexity 308.92\n",
      "| epoch 1 |  iter 501 / 1327 | time 106[s] | perplexity 305.72\n",
      "| epoch 1 |  iter 521 / 1327 | time 111[s] | perplexity 303.48\n",
      "| epoch 1 |  iter 541 / 1327 | time 115[s] | perplexity 315.29\n",
      "| epoch 1 |  iter 561 / 1327 | time 120[s] | perplexity 284.67\n",
      "| epoch 1 |  iter 581 / 1327 | time 125[s] | perplexity 259.58\n",
      "| epoch 1 |  iter 601 / 1327 | time 129[s] | perplexity 337.73\n",
      "| epoch 1 |  iter 621 / 1327 | time 134[s] | perplexity 312.43\n",
      "| epoch 1 |  iter 641 / 1327 | time 138[s] | perplexity 279.31\n",
      "| epoch 1 |  iter 661 / 1327 | time 143[s] | perplexity 269.68\n",
      "| epoch 1 |  iter 681 / 1327 | time 147[s] | perplexity 228.95\n",
      "| epoch 1 |  iter 701 / 1327 | time 152[s] | perplexity 253.14\n",
      "| epoch 1 |  iter 721 / 1327 | time 157[s] | perplexity 259.36\n",
      "| epoch 1 |  iter 741 / 1327 | time 162[s] | perplexity 223.41\n",
      "| epoch 1 |  iter 761 / 1327 | time 166[s] | perplexity 234.70\n",
      "| epoch 1 |  iter 781 / 1327 | time 171[s] | perplexity 217.30\n",
      "| epoch 1 |  iter 801 / 1327 | time 175[s] | perplexity 243.82\n",
      "| epoch 1 |  iter 821 / 1327 | time 180[s] | perplexity 225.13\n",
      "| epoch 1 |  iter 841 / 1327 | time 184[s] | perplexity 227.88\n",
      "| epoch 1 |  iter 861 / 1327 | time 189[s] | perplexity 223.62\n",
      "| epoch 1 |  iter 881 / 1327 | time 193[s] | perplexity 204.73\n",
      "| epoch 1 |  iter 901 / 1327 | time 199[s] | perplexity 252.64\n",
      "| epoch 1 |  iter 921 / 1327 | time 203[s] | perplexity 230.63\n",
      "| epoch 1 |  iter 941 / 1327 | time 208[s] | perplexity 231.10\n",
      "| epoch 1 |  iter 961 / 1327 | time 212[s] | perplexity 245.56\n",
      "| epoch 1 |  iter 981 / 1327 | time 217[s] | perplexity 227.11\n",
      "| epoch 1 |  iter 1001 / 1327 | time 221[s] | perplexity 193.76\n",
      "| epoch 1 |  iter 1021 / 1327 | time 226[s] | perplexity 226.63\n",
      "| epoch 1 |  iter 1041 / 1327 | time 230[s] | perplexity 208.84\n",
      "| epoch 1 |  iter 1061 / 1327 | time 235[s] | perplexity 198.57\n",
      "| epoch 1 |  iter 1081 / 1327 | time 239[s] | perplexity 168.86\n",
      "| epoch 1 |  iter 1101 / 1327 | time 244[s] | perplexity 191.73\n",
      "| epoch 1 |  iter 1121 / 1327 | time 248[s] | perplexity 226.93\n",
      "| epoch 1 |  iter 1141 / 1327 | time 253[s] | perplexity 208.81\n",
      "| epoch 1 |  iter 1161 / 1327 | time 257[s] | perplexity 199.54\n",
      "| epoch 1 |  iter 1181 / 1327 | time 262[s] | perplexity 192.40\n",
      "| epoch 1 |  iter 1201 / 1327 | time 266[s] | perplexity 164.05\n",
      "| epoch 1 |  iter 1221 / 1327 | time 271[s] | perplexity 159.31\n",
      "| epoch 1 |  iter 1241 / 1327 | time 275[s] | perplexity 188.74\n",
      "| epoch 1 |  iter 1261 / 1327 | time 280[s] | perplexity 173.22\n",
      "| epoch 1 |  iter 1281 / 1327 | time 285[s] | perplexity 180.43\n",
      "| epoch 1 |  iter 1301 / 1327 | time 290[s] | perplexity 222.82\n",
      "| epoch 1 |  iter 1321 / 1327 | time 294[s] | perplexity 210.95\n",
      "| epoch 2 |  iter 1 / 1327 | time 296[s] | perplexity 225.76\n",
      "| epoch 2 |  iter 21 / 1327 | time 300[s] | perplexity 204.88\n",
      "| epoch 2 |  iter 41 / 1327 | time 305[s] | perplexity 190.66\n",
      "| epoch 2 |  iter 61 / 1327 | time 309[s] | perplexity 177.56\n",
      "| epoch 2 |  iter 81 / 1327 | time 314[s] | perplexity 159.72\n",
      "| epoch 2 |  iter 101 / 1327 | time 318[s] | perplexity 152.86\n",
      "| epoch 2 |  iter 121 / 1327 | time 323[s] | perplexity 160.47\n",
      "| epoch 2 |  iter 141 / 1327 | time 327[s] | perplexity 181.26\n",
      "| epoch 2 |  iter 161 / 1327 | time 332[s] | perplexity 192.64\n",
      "| epoch 2 |  iter 181 / 1327 | time 337[s] | perplexity 199.85\n",
      "| epoch 2 |  iter 201 / 1327 | time 341[s] | perplexity 185.62\n",
      "| epoch 2 |  iter 221 / 1327 | time 346[s] | perplexity 183.55\n",
      "| epoch 2 |  iter 241 / 1327 | time 350[s] | perplexity 177.09\n",
      "| epoch 2 |  iter 261 / 1327 | time 355[s] | perplexity 187.02\n",
      "| epoch 2 |  iter 281 / 1327 | time 359[s] | perplexity 186.43\n",
      "| epoch 2 |  iter 301 / 1327 | time 364[s] | perplexity 166.66\n",
      "| epoch 2 |  iter 321 / 1327 | time 368[s] | perplexity 139.77\n",
      "| epoch 2 |  iter 341 / 1327 | time 373[s] | perplexity 173.09\n",
      "| epoch 2 |  iter 361 / 1327 | time 379[s] | perplexity 199.05\n",
      "| epoch 2 |  iter 381 / 1327 | time 384[s] | perplexity 156.25\n",
      "| epoch 2 |  iter 401 / 1327 | time 390[s] | perplexity 168.21\n",
      "| epoch 2 |  iter 421 / 1327 | time 396[s] | perplexity 156.54\n",
      "| epoch 2 |  iter 441 / 1327 | time 401[s] | perplexity 165.13\n",
      "| epoch 2 |  iter 461 / 1327 | time 406[s] | perplexity 157.14\n",
      "| epoch 2 |  iter 481 / 1327 | time 413[s] | perplexity 157.60\n",
      "| epoch 2 |  iter 501 / 1327 | time 419[s] | perplexity 170.42\n",
      "| epoch 2 |  iter 521 / 1327 | time 424[s] | perplexity 174.20\n",
      "| epoch 2 |  iter 541 / 1327 | time 430[s] | perplexity 175.84\n",
      "| epoch 2 |  iter 561 / 1327 | time 436[s] | perplexity 154.85\n",
      "| epoch 2 |  iter 581 / 1327 | time 442[s] | perplexity 138.36\n",
      "| epoch 2 |  iter 601 / 1327 | time 447[s] | perplexity 192.23\n",
      "| epoch 2 |  iter 621 / 1327 | time 452[s] | perplexity 183.98\n",
      "| epoch 2 |  iter 641 / 1327 | time 457[s] | perplexity 165.34\n",
      "| epoch 2 |  iter 661 / 1327 | time 462[s] | perplexity 156.92\n",
      "| epoch 2 |  iter 681 / 1327 | time 467[s] | perplexity 131.15\n",
      "| epoch 2 |  iter 701 / 1327 | time 472[s] | perplexity 151.68\n",
      "| epoch 2 |  iter 721 / 1327 | time 476[s] | perplexity 161.15\n",
      "| epoch 2 |  iter 741 / 1327 | time 482[s] | perplexity 134.50\n",
      "| epoch 2 |  iter 761 / 1327 | time 487[s] | perplexity 129.82\n",
      "| epoch 2 |  iter 781 / 1327 | time 493[s] | perplexity 135.39\n",
      "| epoch 2 |  iter 801 / 1327 | time 498[s] | perplexity 148.14\n",
      "| epoch 2 |  iter 821 / 1327 | time 503[s] | perplexity 146.52\n",
      "| epoch 2 |  iter 841 / 1327 | time 508[s] | perplexity 144.94\n",
      "| epoch 2 |  iter 861 / 1327 | time 513[s] | perplexity 148.06\n",
      "| epoch 2 |  iter 881 / 1327 | time 518[s] | perplexity 131.79\n",
      "| epoch 2 |  iter 901 / 1327 | time 523[s] | perplexity 168.47\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0992cd6e1e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# 勾配クリッピングを適用して学習\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/deep-learning-from-scratch-2/common/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# 勾配を求め、パラメータを更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 共有された重みを1つに集約\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmax_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/deep-learning-from-scratch-2/ch06/rnnlm.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/deep-learning-from-scratch-2/common/time_layers.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dhs)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0mdxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/deep-learning-from-scratch-2/common/time_layers.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dh_next, dc_next)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mdA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mdWh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mdWx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "from rnnlm import Rnnlm\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100 # RNNの隠れ状態ベクトルの要素数\n",
    "time_size = 35 # RNNを展開するサイズ\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 学習データの読み込み\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# モデルの生成\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "# 勾配クリッピングを適用して学習\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))\n",
    "\n",
    "# テストデータで評価\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('test perplexity', ppl_test)\n",
    "\n",
    "# パラメータの保存\n",
    "model.save_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 RNNLMのさらなる改善\n",
    "- LSTMレイヤの多層化\n",
    "- Dropoutを使用（深さ方向にのみ適用）\n",
    "- 重み共有（EmbeddingレイヤとAffineレイヤで重み共有）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.np import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "class BetterRnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650, hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, word_vec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # ３つの改善\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeAffine(embed_W.T, affine_b) # 重みの共有\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layer = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "        \n",
    "        # 全ての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def predict(self, xs, train_flg=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flg = trian_flg\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "    \n",
    "    def forward(self, xs, ts, train_flg=True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()\n",
    "        \n",
    "    def save_params(self, file_name='Rnnlm.pkl'):\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(self.params, f)\n",
    "            \n",
    "    def load_params(self, file_name='Rnnlm.pkl'):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            self.params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改善したBetterRnnlmクラスで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 2 |  iter 1 / 1327 | time 0[s] | perplexity 237.60\n",
      "| epoch 2 |  iter 21 / 1327 | time 3[s] | perplexity 149.69\n",
      "| epoch 2 |  iter 41 / 1327 | time 6[s] | perplexity 141.65\n",
      "| epoch 2 |  iter 61 / 1327 | time 9[s] | perplexity 133.76\n",
      "| epoch 2 |  iter 81 / 1327 | time 12[s] | perplexity 116.26\n",
      "| epoch 2 |  iter 101 / 1327 | time 16[s] | perplexity 110.92\n",
      "| epoch 2 |  iter 121 / 1327 | time 19[s] | perplexity 123.08\n",
      "| epoch 2 |  iter 141 / 1327 | time 23[s] | perplexity 137.31\n",
      "| epoch 2 |  iter 161 / 1327 | time 26[s] | perplexity 148.24\n",
      "| epoch 2 |  iter 181 / 1327 | time 30[s] | perplexity 153.32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-06e5f328a3da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mbast_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/deep-learning-from-scratch-2/common/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# 勾配を求め、パラメータを更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 共有された重みを1つに集約\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmax_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/deep-learning-from-scratch-2/ch06/rnnlm.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/deep-learning-from-scratch-2/common/time_layers.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mdx\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mdx\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mdx\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# ignore_labelに該当するデータは勾配を0にする\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common import config\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "batch_size = 20\n",
    "word_vec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "dropout = 0.5\n",
    "\n",
    "# 学習データの読み込み\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_val, _, _ = ptb.load_data('val')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "triner = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "bast_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size, time_size=time_size, max_grad=max_grad)\n",
    "    \n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('valid perplecity:', ppl)\n",
    "    \n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "        model.reset_state()\n",
    "        print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
